{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOuVamreHqVL9YEImzWv6BR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaunck96/Linkedin_ChatBot/blob/main/Linkedin_Content_Inferencer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8d9AEwhuHpN",
        "outputId": "7bf399fa-db58-444a-d5f0-2703c1cc07a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/211.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m194.6/211.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.31.0)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2023.11.17)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13538 sha256=fd46413aedf3cf5d20df671862430851a8a42bdbe30d690397a1c1ecfb5ac047\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3340 sha256=88977a2aa863d5aba6bb9ef6df905919492e7f96a97ae2411c0605a9957e8245\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398381 sha256=aeefd279ed102cffe51eaa4d72fd7b360f66d51ce408b012d32cafcb243b5965\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=365dcaee3bfbc4cb31c4b27c7cbce78e1b2b1f1e7811452929bccfe487f508cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.1\n",
            "Collecting scrapetube==2.5.1\n",
            "  Downloading scrapetube-2.5.1-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from scrapetube==2.5.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from scrapetube==2.5.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (2023.11.17)\n",
            "Installing collected packages: scrapetube\n",
            "Successfully installed scrapetube-2.5.1\n",
            "Collecting pytube==15.0.0\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting huggingsound==0.1.6\n",
            "  Downloading huggingsound-0.1.6-py3-none-any.whl (28 kB)\n",
            "Collecting datasets<3.0.0,>=2.6.1 (from huggingsound==0.1.6)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiwer<3.0.0,>=2.5.1 (from huggingsound==0.1.6)\n",
            "  Downloading jiwer-2.6.0-py3-none-any.whl (20 kB)\n",
            "Collecting librosa<0.10.0,>=0.9.2 (from huggingsound==0.1.6)\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch!=1.12.0,<1.13.0,>=1.7 (from huggingsound==0.1.6)\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.23.1 in /usr/local/lib/python3.10/dist-packages (from huggingsound==0.1.6) (4.35.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.4.1)\n",
            "Collecting multiprocess (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (6.0.1)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer<3.0.0,>=2.5.1->huggingsound==0.1.6) (8.1.7)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer<3.0.0,>=2.5.1->huggingsound==0.1.6)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (4.4.2)\n",
            "Collecting resampy>=0.2.2 (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6)\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,<1.13.0,>=1.7->huggingsound==0.1.6) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (0.4.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (4.0.3)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (4.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2023.11.17)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2023.3.post1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.16.0)\n",
            "Installing collected packages: torch, rapidfuzz, pyarrow-hotfix, dill, resampy, multiprocess, jiwer, librosa, datasets, huggingsound\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.1\n",
            "    Uninstalling librosa-0.10.1:\n",
            "      Successfully uninstalled librosa-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.15.0 dill-0.3.7 huggingsound-0.1.6 jiwer-2.6.0 librosa-0.9.2 multiprocess-0.70.15 pyarrow-hotfix-0.6 rapidfuzz-2.13.7 resampy-0.4.2 torch-1.12.1\n",
            "Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (2023.11.17)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2023.11.17)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n",
            "Collecting faster-whisper==0.9.0\n",
            "  Downloading faster_whisper-0.9.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av==10.* (from faster-whisper==0.9.0)\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.17 (from faster-whisper==0.9.0)\n",
            "  Downloading ctranslate2-3.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==0.9.0) (0.19.4)\n",
            "Collecting tokenizers<0.15,>=0.13 (from faster-whisper==0.9.0)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<2,>=1.14 (from faster-whisper==0.9.0)\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (1.23.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (23.2)\n",
            "Collecting coloredlogs (from onnxruntime<2,>=1.14->faster-whisper==0.9.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.9.0) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.9.0) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.9.0) (1.12)\n",
            "Collecting huggingface-hub>=0.13 (from faster-whisper==0.9.0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==0.9.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper==0.9.0) (1.3.0)\n",
            "Installing collected packages: av, humanfriendly, ctranslate2, huggingface-hub, coloredlogs, tokenizers, onnxruntime, faster-whisper\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed av-10.0.0 coloredlogs-15.0.1 ctranslate2-3.23.0 faster-whisper-0.9.0 huggingface-hub-0.17.3 humanfriendly-10.0 onnxruntime-1.16.3 tokenizers-0.14.1\n",
            "Collecting eyed3==0.9.7\n",
            "  Downloading eyed3-0.9.7-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.1/246.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coverage[toml]<6.0.0,>=5.3.1 (from eyed3==0.9.7)\n",
            "  Downloading coverage-5.5-cp310-cp310-manylinux1_x86_64.whl (238 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation<3.0.0,>=2.1.0 (from eyed3==0.9.7)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting filetype<2.0.0,>=1.0.7 (from eyed3==0.9.7)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from coverage[toml]<6.0.0,>=5.3.1->eyed3==0.9.7) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation<3.0.0,>=2.1.0->eyed3==0.9.7) (23.2)\n",
            "Installing collected packages: filetype, deprecation, coverage, eyed3\n",
            "Successfully installed coverage-5.5 deprecation-2.1.0 eyed3-0.9.7 filetype-1.2.0\n",
            "Collecting tiktoken==0.5.1\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (2023.11.17)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.5.1\n",
            "Collecting langchain==0.0.340\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.9.1)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.340)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.340)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.340)\n",
            "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.340)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.340) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.340) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.340 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting youtube-comment-downloader==0.1.70\n",
            "  Downloading youtube_comment_downloader-0.1.70-py3-none-any.whl (7.9 kB)\n",
            "Collecting dateparser (from youtube-comment-downloader==0.1.70)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-comment-downloader==0.1.70) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (2023.3.post1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (2023.6.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dateparser->youtube-comment-downloader==0.1.70) (1.16.0)\n",
            "Installing collected packages: dateparser, youtube-comment-downloader\n",
            "Successfully installed dateparser-1.2.0 youtube-comment-downloader-0.1.70\n",
            "Collecting guardrails-ai\n",
            "  Downloading guardrails_ai-0.3.1-py3-none-any.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.1/146.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting eliot<2.0.0,>=1.15.0 (from guardrails-ai)\n",
            "  Downloading eliot-1.15.0-py3-none-any.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting eliot-tree<22.0.0,>=21.0.0 (from guardrails-ai)\n",
            "  Downloading eliot_tree-21.0.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting griffe<0.37.0,>=0.36.9 (from guardrails-ai)\n",
            "  Downloading griffe-0.36.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml<5.0.0,>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (4.9.3)\n",
            "Requirement already satisfied: openai<2 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (0.28.0)\n",
            "Requirement already satisfied: pydantic<2.5,>=1.10.9 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (2.8.2)\n",
            "Collecting regex<2024.0.0,>=2023.10.3 (from guardrails-ai)\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich<14.0.0,>=13.6.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (13.7.0)\n",
            "Collecting rstr<4.0.0,>=3.2.2 (from guardrails-ai)\n",
            "  Downloading rstr-3.2.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tenacity>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (8.2.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (0.9.0)\n",
            "Collecting typing-extensions<5.0.0,>=4.8.0 (from guardrails-ai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eliot<2.0.0,>=1.15.0->guardrails-ai) (1.16.0)\n",
            "Collecting zope.interface (from eliot<2.0.0,>=1.15.0->guardrails-ai)\n",
            "  Downloading zope.interface-6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.1/247.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent>=0.11.8 (from eliot<2.0.0,>=1.15.0->guardrails-ai)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boltons>=19.0.1 (from eliot<2.0.0,>=1.15.0->guardrails-ai)\n",
            "  Downloading boltons-23.1.1-py2.py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.3/195.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from eliot<2.0.0,>=1.15.0->guardrails-ai)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath>=0.7.1 (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting iso8601>=0.1.10 (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai)\n",
            "  Downloading iso8601-2.1.0-py3-none-any.whl (7.5 kB)\n",
            "Collecting colored>=1.4.2 (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai)\n",
            "  Downloading colored-2.2.3-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai) (0.12.0)\n",
            "Collecting colorama>=0.4 (from griffe<0.37.0,>=0.36.9->guardrails-ai)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<2->guardrails-ai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<2->guardrails-ai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<2->guardrails-ai) (3.9.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.9.0->guardrails-ai) (8.1.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->guardrails-ai) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (4.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->eliot<2.0.0,>=1.15.0->guardrails-ai) (67.7.2)\n",
            "Installing collected packages: boltons, zope.interface, typing-extensions, rstr, regex, pyrsistent, orjson, jmespath, iso8601, colored, colorama, griffe, eliot, eliot-tree, guardrails-ai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2023.6.3\n",
            "    Uninstalling regex-2023.6.3:\n",
            "      Successfully uninstalled regex-2023.6.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed boltons-23.1.1 colorama-0.4.6 colored-2.2.3 eliot-1.15.0 eliot-tree-21.0.0 griffe-0.36.9 guardrails-ai-0.3.1 iso8601-2.1.0 jmespath-1.0.1 orjson-3.9.10 pyrsistent-0.20.0 regex-2023.10.3 rstr-3.2.2 typing-extensions-4.9.0 zope.interface-6.1\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting newsapi-python\n",
            "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from newsapi-python) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2023.11.17)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install newspaper3k\n",
        "!pip install scrapetube==2.5.1\n",
        "!pip install pytube==15.0.0\n",
        "!pip install huggingsound==0.1.6\n",
        "!pip install transformers==4.35.2\n",
        "!pip install requests==2.31.0\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install openai==0.28\n",
        "!pip install faster-whisper==0.9.0\n",
        "!pip install eyed3==0.9.7\n",
        "!pip install tiktoken==0.5.1\n",
        "!pip install langchain==0.0.340\n",
        "!pip install youtube-comment-downloader==0.1.70\n",
        "!pip install guardrails-ai\n",
        "!pip install -q streamlit\n",
        "!pip install newsapi-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scrapetube\n",
        "from pytube import YouTube\n",
        "import os\n",
        "import librosa\n",
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import os\n",
        "import openai\n",
        "import regex as re\n",
        "import json\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from googleapiclient.discovery import build\n",
        "import regex as re\n",
        "from transformers import pipeline\n",
        "from faster_whisper import WhisperModel\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "from faster_whisper import WhisperModel\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "import re\n",
        "from urllib import parse\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import ast\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from itertools import islice\n",
        "from youtube_comment_downloader import *\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from itertools import islice\n",
        "from youtube_comment_downloader import *\n",
        "from pytube import YouTube\n",
        "import cv2\n",
        "import base64\n",
        "import requests\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from moviepy import editor\n",
        "import os\n",
        "import torch\n",
        "import imageio\n",
        "import os\n",
        "import requests\n",
        "import googleapiclient.discovery\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
        "from langchain.llms import OpenAI\n",
        "import requests\n",
        "import requests\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVda29-RvBNG",
        "outputId": "0e214a6f-d356-4194-f0a2-577a1c9757ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def activity_data_reader_trigger(path=r'/content/post_details.csv')\n",
        "  activity_data = pd.read_csv(path)\n",
        "  activity_data['post_info'] = activity_data['post_info'].astype(str).apply(lambda x: x.replace(\"\\n\",\"\"))\n",
        "  activity_data['like_count'] = activity_data['like_count'].astype(str).apply(lambda x: x.replace(\"\\n\",\"\")[:4])\n",
        "  activity_data['date_of_post'] = activity_data['date_of_post'].astype(str).apply(lambda x: x.replace(\"\\n\",\"\"))\n",
        "  input_to_llm = \"\"\n",
        "  for index in activity_data.index:\n",
        "    input_to_llm+=\"Post Description Number {}: \".format(index)+str(activity_data.at[index, 'post_info'])+\"Like Count : \"+str(activity_data.at[index, 'like_count'])+\"\\n\\n\"\n",
        "  return input_to_llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "RW6VitZ8CZmA",
        "outputId": "0263bef1-1fa0-4468-98ad-3c73af60b563"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                          post_info date_of_post  \\\n",
              "0           0  \\n\\n\\n As the year draws to an end, one can on...     1yr •      \n",
              "1           1  \\n\\n\\n While at Google, until recently, there ...          NaN   \n",
              "2           2  \\n\\n\\n Recently we celebrated One Year of Chat...          NaN   \n",
              "3           3  \\n\\n\\n One of the biggest challenges in adopti...          NaN   \n",
              "\n",
              "  like_count  \n",
              "0         76  \n",
              "1         31  \n",
              "2         51  \n",
              "3         80  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41b42602-dc93-4505-bfc4-6bd95275d3b8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>post_info</th>\n",
              "      <th>date_of_post</th>\n",
              "      <th>like_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\n\\n As the year draws to an end, one can on...</td>\n",
              "      <td>1yr •</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\n\\n While at Google, until recently, there ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>\\n\\n\\n Recently we celebrated One Year of Chat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\n\\n\\n One of the biggest challenges in adopti...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41b42602-dc93-4505-bfc4-6bd95275d3b8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41b42602-dc93-4505-bfc4-6bd95275d3b8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41b42602-dc93-4505-bfc4-6bd95275d3b8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-620eebb7-9839-484e-84b9-3c4b0f7d2fc8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-620eebb7-9839-484e-84b9-3c4b0f7d2fc8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-620eebb7-9839-484e-84b9-3c4b0f7d2fc8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class prompt_template_constructor():\n",
        "  def __init__(self, prompt_template_type='Entity Extraction'):\n",
        "    self.prompt_template_type = prompt_template_type\n",
        "    self.response_schemas = [\n",
        "          ResponseSchema(name=\"Dummy\", description=\"Dummy Template for class initialization\"),\n",
        "      ]\n",
        "    self.prompt = ChatPromptTemplate(\n",
        "          messages=[\n",
        "              HumanMessagePromptTemplate.from_template(\"\"\"\n",
        "              Dummy Chat Prompt Template for class initialization\n",
        "              \"\"\")\n",
        "          ],\n",
        "          input_variables=[\"question\"],\n",
        "          partial_variables={\"format_instructions\": \"\"}\n",
        "      )\n",
        "  def output_parser_initiator(self):\n",
        "    output_parser = StructuredOutputParser.from_response_schemas(self.response_schemas)\n",
        "    return(output_parser.get_format_instructions())\n",
        "\n",
        "  def prompt_template_assignment(self):\n",
        "    if self.prompt_template_type == 'Entity Extraction':\n",
        "      self.response_schemas = [\n",
        "          ResponseSchema(name=\"Post ID\", description=\"ID of the Linkedin Post\"),\n",
        "          ResponseSchema(name=\"Post Topic\", description=\"Topic Described By Linkedin Post\")\n",
        "      ]\n",
        "      format_instructions = self.output_parser_initiator()\n",
        "      self.prompt = ChatPromptTemplate(\n",
        "          messages=[\n",
        "              HumanMessagePromptTemplate.from_template(\"\"\"\n",
        "              You are a helpful assistant who evaluates Linkedin Activity by a user over a given time period split by \"\\n\\n\". Generate a one line description of topic discussed in the each of the posts.\n",
        "              {format_instructions}\n",
        "              Linkedin Articles: {question}\n",
        "\n",
        "              Return a topic for every post input. If the topic cannot be identified for a particular post, assign Uidentified as topic for that post.\"\"\")\n",
        "          ],\n",
        "          input_variables=[\"question\"],\n",
        "          partial_variables={\"format_instructions\": format_instructions}\n",
        "      )\n",
        "      return self.prompt\n",
        "\n",
        "    elif self.prompt_template_type == 'Topic List Summarizer':\n",
        "      response_schemas = [\n",
        "          ResponseSchema(name=\"Topic List\", description=\"List of topics categorized into high level and sub topics\")\n",
        "      ]\n",
        "      format_instructions = self.output_parser_initiator()\n",
        "      self.prompt = ChatPromptTemplate(\n",
        "          messages=[\n",
        "              HumanMessagePromptTemplate.from_template(\"\"\"\n",
        "              You are a helpful assistant who evaluates Linkedin Activity Post Topics separated by \"\\n\\n\". Group them together and provide a list of high level and sub topics.\n",
        "              {format_instructions}\n",
        "              Linkedin Articles: {question}\n",
        "\n",
        "              Return a topic for every post input. If the topic cannot be identified for a particular post, assign Uidentified as topic for that post.\"\"\")\n",
        "          ],\n",
        "          input_variables=[\"question\"],\n",
        "          partial_variables={\"format_instructions\": format_instructions}\n",
        "      )\n",
        "\n",
        "      return self.prompt\n",
        "\n",
        "\n",
        "class llm_input_utils:\n",
        "  def __init__(self, encoding_name = \"gpt-3.5-turbo-16k\", path = r'/content/post_details.csv', task = 'Entity Extraction'):\n",
        "    self.input_to_llm = \"\"\n",
        "    self.encoding_name = encoding_name\n",
        "    self.file_path = path\n",
        "    self.task = task\n",
        "    self.output_json = \"\"\n",
        "    self.post_data_file_path = r'/content/activity_with_inference.csv'\n",
        "\n",
        "  def activity_data_reader_trigger(self):\n",
        "    activity_data = pd.read_csv(self.file_path)\n",
        "    activity_data['post_info'] = activity_data['post_info'].astype(str).apply(lambda x: x.replace(\"\\n\",\"\"))\n",
        "    activity_data['like_count'] = activity_data['like_count'].astype(str).apply(lambda x: x.replace(\"\\n\",\"\")[:4])\n",
        "    activity_data['date_of_post'] = activity_data['date_of_post'].astype(str).apply(lambda x: x.replace(\"\\n\",\"\"))\n",
        "    for index in activity_data.index:\n",
        "      self.input_to_llm+=\"Post Description Number {}: \".format(index)+str(activity_data.at[index, 'post_info'])+\"Like Count : \"+str(activity_data.at[index, 'like_count'])+\"\\n\\n\"\n",
        "\n",
        "    self.llm_formulator()\n",
        "\n",
        "  def linkedin_activity_categorizer(self):\n",
        "    activity_data = pd.read_csv(self.post_data_file_path)\n",
        "    post_topics = \"\\n\\n\".join(list(activity_data['Topic'].unique()))\n",
        "    self.task = \"Topic List Summarizer\"\n",
        "    print(\"Starting Topic Estimation\")\n",
        "    self.llm_formulator()\n",
        "    print(\"Topic Summarizer Completed\")\n",
        "    print(self.output_json)\n",
        "\n",
        "  def num_tokens_from_string(self, string=\"\"):\n",
        "      \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "      if string == \"\":\n",
        "        encoding = tiktoken.encoding_for_model(self.encoding_name)\n",
        "        num_tokens = len(encoding.encode(self.input_to_llm))\n",
        "        return num_tokens\n",
        "      else:\n",
        "        encoding = tiktoken.encoding_for_model(self.encoding_name)\n",
        "        num_tokens = len(encoding.encode(string))\n",
        "        return num_tokens\n",
        "\n",
        "  def post_description_chunker(self):\n",
        "    chunks = []\n",
        "    chunk_master = []\n",
        "    for i in self.input_to_llm.split(\"\\n\\n\"):\n",
        "      chunks.append(i)\n",
        "      if self.num_tokens_from_string(' '.join(chunks))>10000:\n",
        "        chunk_master.append('\\n\\n'.join(chunks))\n",
        "        chunks = []\n",
        "    return chunk_master\n",
        "\n",
        "  def llm_formulator(self):\n",
        "    prompt_template_final = prompt_template_constructor(prompt_template_type=self.task).prompt_template_assignment()\n",
        "    prompt = prompt_template_final\n",
        "    chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.5, openai_api_key = \"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\")\n",
        "    transcription_token_length = self.num_tokens_from_string()\n",
        "    if transcription_token_length<16000:\n",
        "      _input = prompt.format_prompt(question=self.input_to_llm)\n",
        "      self.output_json = chat_model(_input.to_messages())\n",
        "      #return(output_parser.parse(output.content))\n",
        "    else:\n",
        "      print(\"Token Limit Exceeded. Chunking and evaluating\")\n",
        "      chunks = self.post_description_chunker()\n",
        "      for chunk in chunks:\n",
        "        _input = prompt.format_prompt(question=chunk)\n",
        "        output = chat_model(_input.to_messages())\n",
        "        self.output_json+=output.content+\"****\"\n",
        "    if self.task == 'Entity Extraction':\n",
        "      self.llm_output_parser()\n",
        "    else:\n",
        "      print(\"Topic Summarizer Completed\")\n",
        "      print(self.output_json)\n",
        "\n",
        "  def llm_output_parser(self):\n",
        "    responses = self.output_json.split(\"****\")\n",
        "    updated_responses = []\n",
        "\n",
        "    for ind in responses:\n",
        "      response_split = ind.split(\"}\\n{\")\n",
        "      for r in response_split:\n",
        "        r = r.replace(\"\\n\\t\",\"\").replace(\"\\n\",\"\").strip()\n",
        "        r = re.sub('\\s+', ' ', r).strip()\n",
        "        r = r.replace(\"json{\",\"\")\n",
        "        r = r.replace(\"```\",\"\")\n",
        "        updated_responses.append(r)\n",
        "\n",
        "    post_info = pd.DataFrame(columns=['Post_ID','Topic'])\n",
        "\n",
        "    for i in updated_responses:\n",
        "      if len(i)>2:\n",
        "        post_details = i.split('''\",\"''')\n",
        "        post_info = post_info.append({'Post_ID': post_details[0].split(\":\")[1].replace('\"',\"\"), 'Topic': post_details[1].split(\":\")[1]}, ignore_index=True)\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "    post_info['Post_ID'] = post_info['Post_ID']\n",
        "    post_info.set_index('Post_ID', inplace=True)\n",
        "    post_info.to_csv(self.post_data_file_path)"
      ],
      "metadata": {
        "id": "359wkmExvww8"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_input_utils(task = 'Entity Extraction').activity_data_reader_trigger()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj9B8daB3SVe",
        "outputId": "9bcc9330-8f11-4b3a-d74b-a7a79629f9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Limit Exceeded. Chunking and evaluating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_input_utils(task = 'Topic List Summarizer').linkedin_activity_categorizer()"
      ],
      "metadata": {
        "id": "1bZDr7OUDaEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ugfEdRNC9uhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}